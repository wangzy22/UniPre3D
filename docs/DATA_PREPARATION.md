# Data Preparation ğŸ—‚ï¸

This document provides detailed instructions for preparing the datasets used in our project. We use two main datasets: ShapeNet-Multiview and ScanNet v2.

## Table of Contents
- [ShapeNet-Multiview Dataset](#shapenet-multiview-dataset)
  - [Option 1: Download from Baidu Cloud](#option-1-download-from-baidu-cloud)
  - [Option 2: Download from HuggingFace](#option-2-download-from-huggingface)
  - [Dataset Structure](#shapenet-dataset-structure)
- [ScanNet v2](#scannet-v2)
  - [Download and Preparation](#download-and-preparation)
  - [Dataset Structure](#scannet-dataset-structure)
- [Acknowledgements](#acknowledgements)

## ShapeNet-Multiview Dataset ğŸ–¼ï¸ (For Object-level Pretraining) <a id="shapenet-multiview-dataset"></a>

ShapeNet-Multiview dataset is a collection of multi-view renderings of 3D models in the ShapeNet dataset.

Our ShapeNet-Multiview dataset is based on the work of [ShapenetRender_more_variation](https://github.com/Xharlie/ShapenetRender_more_variation). We configured different parameters specifically for compatibility with our framework. It provides high-quality multi-view renderings of 3D models with the following features:

- 24 views per model
- Resolution: 128 x 128
- Modalities: RGB and point cloud
- Camera parameters and metadata included

### Dataset Download

**Option 1: Download from [Baidu Cloud](https://pan.baidu.com/s/1XIuxMYMhXeIhd9Bf8XZuoQ?pwd=ve54)**
```bash
Link: https://pan.baidu.com/s/1XIuxMYMhXeIhd9Bf8XZuoQ?pwd=ve54
Extraction Code: ve54
```

**Option 2: Download from [HuggingFace](https://huggingface.co/datasets/Yanran21/Shapenet_multiview)**
```bash
https://huggingface.co/datasets/Yanran21/Shapenet_multiview
```

### Dataset Structure

The dataset is split into multiple zip files, which need to be downloaded, merged, and extracted. The commands for merging and extracting are as follows:
```bash
zip -s 0 shapenet_dataset.zip --out shapenet_dataset_merged.zip
unzip shapenet_dataset_merged.zip
```

After downloading and extracting, your dataset should follow this structure:
```
shapenet_dataset_merged/
â”œâ”€â”€ image/
â”‚   â”œâ”€â”€ 02691156/   
â”‚   â”‚   â”œâ”€â”€ 10155655850468db78d106ce0a280f87/
â”‚   â”‚   â”‚   â”œâ”€â”€ easy/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ 00.png
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ 00.txt
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ 01.png
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ 01.txt
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ ...
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ rendering_metadata.txt
â”‚   â”‚   â”‚   â”œâ”€â”€ pts/
â”‚   â”‚   â”‚   â”‚   â”œâ”€â”€ 02691156-10155655850468db78d106ce0a280f87.npy
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ 02747177/
â”‚       â”œâ”€â”€ ...
```

where `rendering_metadata.txt` contains the camera parameters and metadata for each view. `pts` contains the point cloud data. `image` contains the rendered images.

For using the dataset, you need to set the `data.dataset_root` in the `configs/dataset/shapenet.yaml` file.

## ScanNet v2 ğŸ  (For Scene-level Pretraining) <a id="scannet-v2"></a>

[ScanNet v2](http://www.scan-net.org/) is a large-scale indoor scene dataset with RGB-D scans and 3D reconstructions.

### Download and Preparation

We use the processed ScanNet dataset provided by [Pointcept](https://github.com/Pointcept/Pointcept?tab=readme-ov-file#scannet-v2).

### ScanNet Dataset Structure
After processing, your ScanNet dataset should look like:
```
scannet/
â”œâ”€â”€ train/
â”‚   â”œâ”€â”€ scene0000_00/
â”‚   â”‚   â”œâ”€â”€ color.npy
â”‚   â”‚   â”œâ”€â”€ coord.npy
â”‚   â”‚   â”œâ”€â”€ normal.npy
â”‚   â”‚   â”œâ”€â”€ instance.npy
â”‚   â”‚   â”œâ”€â”€ segment20.npy
â”‚   â”‚   â””â”€â”€ segment200.npy
â”‚   â””â”€â”€ ...
â”œâ”€â”€ val/
â”‚   â”œâ”€â”€ scene0000_00/
â”‚   â”‚   â”œâ”€â”€ color.npy
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ ...
â”œâ”€â”€ test/
â”‚   â”œâ”€â”€ scene0000_00/
â”‚   â”‚   â”œâ”€â”€ color.npy
â”‚   â”‚   â””â”€â”€ ...
â”‚   â””â”€â”€ ...
```

For using the dataset, you need to set the `data.dataset_root` in the `configs/dataset/scannet.yaml` file.